{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyMvcDrc5TXdqugp/Kt7/4Re"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZwxN-FvJJ9F",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1662977206806,
     "user_tz": -540,
     "elapsed": 2604,
     "user": {
      "displayName": "최민동",
      "userId": "09574473408615109689"
     }
    },
    "outputId": "1c7f2812-8c08-4715-e30a-d996d67ac2d5",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/drive/MyDrive/PlanetA/Geo_MM/PlanetA"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqL5xuBgJd3l",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1662977206807,
     "user_tz": -540,
     "elapsed": 17,
     "user": {
      "displayName": "최민동",
      "userId": "09574473408615109689"
     }
    },
    "outputId": "1dc403ba-739b-4d4c-f0dc-0773b309de90",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "from data.f1_score import f1_score\n",
    "from data.Data_Loader_Seperated import create_data_loaders\n",
    "from model.mm_SNUNet_do import SNUNet_ECAM\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, loss_type, gpu):\n",
    "    model.train()\n",
    "    len_loader = len(data_loader)\n",
    "    total_loss = 0.\n",
    "    for_val = 0.\n",
    "    for iter, batch in enumerate(data_loader):\n",
    "        # inserted multi-modality here\n",
    "        if gpu:\n",
    "            S2_A = Variable(batch['A']['S2'].float()).cuda()\n",
    "            S2_B = Variable(batch['B']['S2'].float()).cuda()\n",
    "            S1_A = Variable(batch['A']['S1'].float()).cuda()\n",
    "            S1_B = Variable(batch['B']['S1'].float()).cuda()\n",
    "            label = torch.squeeze(Variable(batch['label'])).cuda()\n",
    "        else:\n",
    "            S2_A = Variable(batch['A']['S2'].float())\n",
    "            S2_B = Variable(batch['B']['S2'].float())\n",
    "            S1_A = Variable(batch['A']['S1'].float())\n",
    "            S1_B = Variable(batch['B']['S1'].float())\n",
    "            label = torch.squeeze(Variable(batch['label']))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(S2_A, S2_B, S1_A, S1_B)\n",
    "        loss = loss_type(output, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for_val += f1_score(torch.max(output.data, 1)[1], label)\n",
    "        total_loss += loss.item()\n",
    "        if iter % 10 == 0:\n",
    "            print(f'Loss :{total_loss / (iter + 1):.3f} F1 :{for_val / (iter + 1):.3f} Iter : {iter}/{len_loader}')\n",
    "    total_loss /= len_loader\n",
    "    for_val /= len_loader\n",
    "    print(f'Loss :{total_loss:.3f} F1 :{for_val:.3f} Iter : {len_loader}/{len_loader}')\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def validate(model, data_loader, gpu):\n",
    "    model.eval()\n",
    "    len_loader = len(data_loader)\n",
    "\n",
    "    boxes = {}\n",
    "    outputs = np.zeros(shape=(len_loader, 96, 96))\n",
    "    labels = np.zeros(shape=(len_loader, 96, 96))\n",
    "    for iter, batch in enumerate(data_loader):\n",
    "        if gpu:\n",
    "            S2_A = Variable(batch['A']['S2'].float()).cuda()\n",
    "            S2_B = Variable(batch['B']['S2'].float()).cuda()\n",
    "            S1_A = Variable(batch['A']['S1'].float()).cuda()\n",
    "            S1_B = Variable(batch['B']['S1'].float()).cuda()\n",
    "            label = torch.squeeze(Variable(batch['label'])).cuda()\n",
    "            box = batch['box']\n",
    "        else:\n",
    "            S2_A = Variable(batch['A']['S2'].float())\n",
    "            S2_B = Variable(batch['B']['S2'].float())\n",
    "            S1_A = Variable(batch['A']['S1'].float())\n",
    "            S1_B = Variable(batch['B']['S1'].float())\n",
    "            label = torch.squeeze(Variable(batch['label']))\n",
    "            box = batch['box']\n",
    "        output = model(S2_A, S2_B, S1_A, S1_B)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        outputs[iter] += predicted.cpu().numpy().squeeze(0)\n",
    "        labels[iter] += label.cpu().numpy()\n",
    "        boxes[str(iter)] = (box[0].item(), box[1].item(), box[2].item())\n",
    "\n",
    "    # Q: 576, 672 (42) R : 672, 480 (35) S: 288, 480 (15)\n",
    "    reconed = plot_return_array(outputs, labels, boxes)\n",
    "    Q_pred, Q_label = reconed['Q']\n",
    "    R_pred, R_label = reconed['R']\n",
    "    S_pred, S_label = reconed['S']\n",
    "\n",
    "    Q_f1 = f1_score(torch.tensor(Q_pred), torch.tensor(Q_label))\n",
    "    R_f1 = f1_score(torch.tensor(R_pred), torch.tensor(R_label))\n",
    "    S_f1 = f1_score(torch.tensor(S_pred), torch.tensor(S_label))\n",
    "\n",
    "    losses = torch.tensor([Q_f1, R_f1, S_f1])\n",
    "    val_loss = torch.mean(losses)\n",
    "\n",
    "    return val_loss, losses\n",
    "\n",
    "\n",
    "def plot_return_array(outputs, labels, boxes):\n",
    "    patch_size = 96\n",
    "\n",
    "    Q_predicted = np.zeros(shape=(576, 672))\n",
    "    Q_label = np.zeros(shape=(576, 672))\n",
    "\n",
    "    R_predicted = np.zeros(shape=(672, 480))\n",
    "    R_label = np.zeros(shape=(672, 480))\n",
    "\n",
    "    S_predicted = np.zeros(shape=(288, 480))\n",
    "    S_label = np.zeros(shape=(288, 480))\n",
    "\n",
    "    to_return = {}\n",
    "    for num in range(0, 42):\n",
    "        j, i, patch_size = boxes[str(num)]\n",
    "        Q_predicted[j:j + patch_size, i:i + patch_size] += outputs[num]\n",
    "        Q_label[j:j + patch_size, i:i + patch_size] += labels[num]\n",
    "    to_return['Q'] = (Q_predicted, Q_label)\n",
    "\n",
    "    for num in range(42, 77):\n",
    "        j, i, patch_size = boxes[str(num)]\n",
    "        R_predicted[j:j + patch_size, i:i + patch_size] += outputs[num]\n",
    "        R_label[j:j + patch_size, i:i + patch_size] += labels[num]\n",
    "    to_return['R'] = (R_predicted, R_label)\n",
    "\n",
    "    for num in range(77, 92):\n",
    "        j, i, patch_size = boxes[str(num)]\n",
    "        S_predicted[j:j + patch_size, i:i + patch_size] += outputs[num]\n",
    "        S_label[j:j + patch_size, i:i + patch_size] += labels[num]\n",
    "    to_return['S'] = (S_predicted, S_label)\n",
    "\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def save_model(exp_dir, epoch, net_name, model, optimizer, best_val_loss):\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "        },\n",
    "        exp_dir / f'{net_name}.pt'\n",
    "    )\n",
    "\n",
    "\n",
    "def train(net_name, gpu):\n",
    "    NUM_EPOCHS = 20\n",
    "    DATA_PATH_TRAIN = '/content/drive/MyDrive/PlanetA/Geo/data/dataset_training'\n",
    "    DATA_PATH_VAL = '/content/drive/MyDrive/PlanetA/Geo/data/dataset_val'\n",
    "    NET_NAME = net_name\n",
    "\n",
    "    model = SNUNet_ECAM()\n",
    "    train_loader = create_data_loaders(data_path=DATA_PATH_TRAIN,\n",
    "                                       transform=True,\n",
    "                                       shuffle=True\n",
    "                                       )\n",
    "    val_loader = create_data_loaders(data_path=DATA_PATH_VAL,\n",
    "                                     val=True,\n",
    "                                     batch_size=1)\n",
    "    weights = torch.FloatTensor(train_loader.dataset.weights)\n",
    "\n",
    "    if gpu:\n",
    "        device = torch.device(f'cuda:{0}' if torch.cuda.is_available() else 'cpu')\n",
    "        torch.cuda.set_device(device)\n",
    "        print('Current cuda device: ', torch.cuda.current_device())\n",
    "        model.to(device=device)\n",
    "        weights = weights.cuda()\n",
    "        # loss_type = nn.NLLLoss(weight=weights).cuda()\n",
    "        loss_type = nn.CrossEntropyLoss(weight=weights).cuda()\n",
    "    else:\n",
    "        # loss_type = nn.NLLLoss(weight=weights)\n",
    "        loss_type = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    print('Parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                 lr=1e-3,\n",
    "                                 weight_decay=1e-3\n",
    "                                 )\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer,\n",
    "                                                       gamma=0.95)\n",
    "    start_epoch = 0\n",
    "    best_val_loss = 0\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "        print(f'Epoch #{epoch + 1:2d} ............... {NET_NAME} ...............')\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, loss_type, gpu=gpu)\n",
    "        scheduler.step()\n",
    "        F1_score, losses = validate(model, val_loader, gpu=gpu)\n",
    "        print(f'F1 of Q, R, S: {losses[0]:.3f}, {losses[1]:.3f}, {losses[2]:.3f}')\n",
    "\n",
    "        if gpu:\n",
    "            train_loss = torch.tensor(train_loss).cuda(non_blocking=True)\n",
    "            F1_score = torch.tensor(F1_score).cuda(non_blocking=True)\n",
    "        else:\n",
    "            train_loss = torch.tensor(train_loss)\n",
    "            F1_score = torch.tensor(F1_score)\n",
    "\n",
    "        is_new_best = F1_score > torch.tensor(best_val_loss)\n",
    "        best_val_loss = max(best_val_loss, F1_score.cpu().numpy())\n",
    "\n",
    "        print(\n",
    "            f'Epoch = {epoch + 1:4d}/{NUM_EPOCHS:4d} TrainLoss = {train_loss:.4g} ',\n",
    "            f'F1 Score = {F1_score:.4g}'\n",
    "        )\n",
    "\n",
    "        if is_new_best:\n",
    "            print(\"@@@@@New Record@@@@@\")\n",
    "            save_model(epoch=epoch,\n",
    "                       model=model,\n",
    "                       net_name=NET_NAME,\n",
    "                       optimizer=optimizer,\n",
    "                       best_val_loss=F1_score,\n",
    "                       exp_dir=Path('/content/drive/MyDrive/PlanetA/Geo_MM_do/Geo/result'))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net_name = [f'new_val_{i}' for i in range(10)]\n",
    "    for name in net_name:\n",
    "        train(name, gpu=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WXluCyVJKeF",
    "outputId": "f3a190da-ec26-48ff-dda5-4e1cc64b7fca",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}